{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b06cf9-aa4d-45e0-a1d0-f85cf56e331a",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import nltk\n",
    "import sys # needed this for certain print options during debugging\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import pickle\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c3e8e2-7579-4ca0-949d-a7a336abdd4a",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#load the dataset\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df = pd.read_csv('data/final_dataset.csv', converters={'ProcessTokens': literal_eval})\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e0f2c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#convert the datatype of processtokens fromm list to string, so that our vectorization works right.\n",
    "df['ProcessTokens'] = df['ProcessTokens'].astype(\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9183de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test_split before normalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(columns=['user_suggestion','review_id', 'year']).copy()\n",
    "y = df['user_suggestion']\n",
    "\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X, y, train_size=0.8)\n",
    "\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size=0.5)\n",
    "\n",
    "#print(X_train.shape), print(y_train.shape)\n",
    "#print(X_valid.shape), print(y_valid.shape)\n",
    "#print(X_test.shape), print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3483537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for NaN-Values\n",
    "#print(pd.isna(X_train).values)\n",
    "#print(pd.isna(y_train).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff490cc-3296-4c27-8560-dcb54f42838e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define text vectorizer\n",
    "count_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76438feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text vectorization with count_vectorizer\n",
    "#vectorization on train_dataset\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "def create_vectorized_dataset_count(data):\n",
    "    list_of_count_vectors = []\n",
    "    data = data.tolist() # converting to a list\n",
    "    count_vector = count_vectorizer.fit_transform(data)\n",
    "    count_array = count_vector.toarray()\n",
    "    dftemp = pd.DataFrame(data=count_array,columns = count_vectorizer.get_feature_names())\n",
    "    #return count_array # this is the 2d\n",
    "    return count_vector\n",
    "\n",
    "count_vector = create_vectorized_dataset_count(X_train['ProcessTokens']) # this becomes our count vectorization vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092efcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform count test data\n",
    "\n",
    "test_count_vector = count_vectorizer.transform(X_test['ProcessTokens'])\n",
    "print(\"n_samples: %d, n_features: %d\" % test_count_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57253233-3da0-4666-989d-1e89dc1eb729",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes with count vector\n",
    "naive_bayes_classifier = MultinomialNB()\n",
    "naive_bayes_classifier.fit(count_vector, y_train)\n",
    "\n",
    "y_prediction = naive_bayes_classifier.predict(test_count_vector)\n",
    "\n",
    "print(\"Multinomial Naive Bayes model accuracy(in %):\", metrics.accuracy_score(y_test, y_prediction)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07028fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knn\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn_clf = knn.fit(count_vector, y_train)\n",
    "knn_y_pred = knn_clf.predict(test_count_vector)\n",
    "\n",
    "\n",
    "print(\"kNN model accuracy(in %):\", metrics.accuracy_score(y_test, knn_y_pred)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742c7bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(count_vector, y_train)\n",
    "lr_y_pred = lr_clf.predict(test_count_vector)\n",
    "\n",
    "\n",
    "print(\"LR model accuracy(in %):\", metrics.accuracy_score(y_test, lr_y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d57ede3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define confusion matriy\n",
    "cm = confusion_matrix(y_test, lr_y_pred)\n",
    "print (\"Accuracy : \", accuracy_score(y_test, lr_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160d5985",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=lr_clf.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2a6907",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(lr_clf, open('lr_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf46733",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"I'm scared and hearing creepy voices. So I'll pause for a moment and write a review while I wait for my heart beat to return to atleast somewhat calmer times. This game is adorable and creepy like my happy tree friends but with the graphics sceme of my childhood (but more bubble and 'clean'). Hello 1990's.What charactes there are (that isnot trying to kill me) were likable and a bit odd. I did do a few noob things though, such as:Oh look a class room full of ghosts from dead children, lets shine my flashlight on them and stand there staring at them..Or, hmm creepy music, I'll turn around and see if I can see what's chasing me.Never before in a game have I been this afraid of finding a locked door.\"\n",
    "user_input_count_vector = count_vectorizer.transform([user_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891017c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickled_model = pickle.load(open('lr_model.pkl', 'rb'))\n",
    "pickled_model.predict(user_input_count_vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "3b7e9cb8e453d6cda0fe8c8dd13f891a1f09162f0e7c66ffeae7751a7aecf00d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
